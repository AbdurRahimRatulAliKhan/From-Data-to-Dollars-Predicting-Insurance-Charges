{"cells":[{"source":"![](image.jpg)\n\n\nDive into the heart of data science with a project that combines healthcare insights and predictive analytics. As a Data Scientist at a top Health Insurance company, you have the opportunity to predict customer healthcare costs using the power of machine learning. Your insights will help tailor services and guide customers in planning their healthcare expenses more effectively.\n\n## Dataset Summary\n\nMeet your primary tool: the `insurance.csv` dataset. Packed with information on health insurance customers, this dataset is your key to unlocking patterns in healthcare costs. Here's what you need to know about the data you'll be working with:\n\n## insurance.csv\n| Column    | Data Type | Description                                                      |\n|-----------|-----------|------------------------------------------------------------------|\n| `age`       | int       | Age of the primary beneficiary.                                  |\n| `sex`       | object    | Gender of the insurance contractor (male or female).             |\n| `bmi`       | float     | Body mass index, a key indicator of body fat based on height and weight. |\n| `children`  | int       | Number of dependents covered by the insurance plan.              |\n| `smoker`    | object    | Indicates whether the beneficiary smokes (yes or no).            |\n| `region`    | object    | The beneficiary's residential area in the US, divided into four regions. |\n| `charges`   | float     | Individual medical costs billed by health insurance.             |\n\n\n\nA bit of data cleaning is key to ensure the dataset is ready for modeling. Once your model is built using the `insurance.csv` dataset, the next step is to apply it to the `validation_dataset.csv`. This new dataset, similar to your training data minus the `charges` column, tests your model's accuracy and real-world utility by predicting costs for new customers.\n\n## Let's Get Started!\n\nThis project is your playground for applying data science in a meaningful way, offering insights that have real-world applications. Ready to explore the data and uncover insights that could revolutionize healthcare planning? Let's begin this exciting journey!","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"id":"6918e18a-c248-4929-b552-7aee2057c0eb","cell_type":"markdown"},{"source":"# Re-run this cell\n# Import required libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\n\n# Loading the insurance dataset\ninsurance_data_path = 'insurance.csv'\ninsurance = pd.read_csv(insurance_data_path)\ninsurance.head()","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"68907f0d-bbd0-4124-b42e-deb83350d20b","nodeType":"const"}}}},"lastExecutedByKernel":null},"id":"81a07c66-a3d4-4fdd-9c3c-7b3a19b80d62","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"age","type":"number"},{"name":"sex","type":"string"},{"name":"bmi","type":"number"},{"name":"children","type":"number"},{"name":"smoker","type":"string"},{"name":"region","type":"string"},{"name":"charges","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"age":[19,18,28,33,32],"sex":["female","male","male","male","male"],"bmi":[27.9,33.77,33,22.705,28.88],"children":[0,1,3,0,0],"smoker":["yes","no","no","no","no"],"region":["southwest","Southeast","southeast","northwest","northwest"],"charges":["16884.924","1725.5523","$4449.462","$21984.47061","$3866.8552"]}},"total_rows":5,"truncation_type":null},"text/plain":"    age     sex     bmi  children smoker     region       charges\n0  19.0  female  27.900       0.0    yes  southwest     16884.924\n1  18.0    male  33.770       1.0     no  Southeast     1725.5523\n2  28.0    male  33.000       3.0     no  southeast     $4449.462\n3  33.0    male  22.705       0.0     no  northwest  $21984.47061\n4  32.0    male  28.880       0.0     no  northwest    $3866.8552","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>bmi</th>\n      <th>children</th>\n      <th>smoker</th>\n      <th>region</th>\n      <th>charges</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19.0</td>\n      <td>female</td>\n      <td>27.900</td>\n      <td>0.0</td>\n      <td>yes</td>\n      <td>southwest</td>\n      <td>16884.924</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18.0</td>\n      <td>male</td>\n      <td>33.770</td>\n      <td>1.0</td>\n      <td>no</td>\n      <td>Southeast</td>\n      <td>1725.5523</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28.0</td>\n      <td>male</td>\n      <td>33.000</td>\n      <td>3.0</td>\n      <td>no</td>\n      <td>southeast</td>\n      <td>$4449.462</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33.0</td>\n      <td>male</td>\n      <td>22.705</td>\n      <td>0.0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>$21984.47061</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32.0</td>\n      <td>male</td>\n      <td>28.880</td>\n      <td>0.0</td>\n      <td>no</td>\n      <td>northwest</td>\n      <td>$3866.8552</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":9}]},{"source":"# Implement model creation and training here\n# Use as many cells as you need\n\n# Full, robust solution — run in one cell\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score as _r2_score\n\n# -------------------------\n# Load data\n# -------------------------\ninsurance = pd.read_csv(\"insurance.csv\")\nvalidation_data = pd.read_csv(\"validation_dataset.csv\")\n\n# -------------------------\n# Clean target: 'charges'\n# -------------------------\n# Remove dollar signs and commas, coerce to float\ninsurance['charges'] = (insurance['charges']\n                        .astype(str)\n                        .str.replace(r'[\\$,]', '', regex=True)\n                        .str.strip()\n                        .replace('', np.nan)\n                        .astype(float))\n\n# -------------------------\n# Define columns\n# -------------------------\ncategorical_cols = ['sex', 'smoker', 'region']\nnumeric_cols = ['age', 'bmi', 'children']\n\n# Basic standardization of string categories (helps avoid small text mismatches)\nfor c in categorical_cols:\n    insurance[c] = insurance[c].astype(str).str.strip().str.lower()\n    # if validation has these columns, standardize them too (if column missing we'll handle later)\n    if c in validation_data.columns:\n        validation_data[c] = validation_data[c].astype(str).str.strip().str.lower()\n\n# Ensure numeric columns are numeric\ninsurance[numeric_cols] = insurance[numeric_cols].apply(pd.to_numeric, errors='coerce')\nvalidation_data[numeric_cols] = validation_data[numeric_cols].apply(pd.to_numeric, errors='coerce')\n\n# Drop rows in training that still have missing critical values\ninsurance = insurance.dropna(subset=numeric_cols + categorical_cols + ['charges'])\n\n# Split features/target\nX = insurance.drop(columns=['charges'])\ny = insurance['charges']\n\n# -------------------------\n# Preprocessing + model pipeline\n# - numeric: median imputation\n# - categorical: constant imputer + OneHotEncoder(handle_unknown='ignore')\n# -------------------------\nnum_transformer = SimpleImputer(strategy='median')\ncat_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', num_transformer, numeric_cols),\n    ('cat', cat_transformer, categorical_cols)\n], remainder='drop')   # drop any other columns\n\nmodel = Pipeline([\n    ('pre', preprocessor),\n    ('reg', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1))\n])\n\n# -------------------------\n# Train / evaluate\n# -------------------------\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel.fit(X_train, y_train)\ny_pred_test = model.predict(X_test)\n\n# save R^2 in variable r2_score as required\nr2_score = float(_r2_score(y_test, y_pred_test))\nprint(\"R^2 on holdout test set:\", r2_score)\n\n# -------------------------\n# Predict on validation set\n# -------------------------\n# Ensure validation contains required feature columns; if not, add missing columns filled with NaN\nfor c in numeric_cols + categorical_cols:\n    if c not in validation_data.columns:\n        validation_data[c] = np.nan\n\n# Make predictions (preprocessor handles missing values)\nval_X = validation_data[numeric_cols + categorical_cols]\nvalidation_preds = model.predict(val_X)\n\n# Enforce minimum charge of 1000\nvalidation_data['predicted_charges'] = np.maximum(validation_preds, 1000.0)\n\n# Final object required by the task:\n# - r2_score  (float)\n# - validation_data  (pandas DataFrame, with 'predicted_charges' column)\nprint(\"\\nSample predictions:\")\nprint(validation_data[['predicted_charges']].head())\n\n# validation_data is the final DataFrame requested\n","metadata":{"executionCancelledAt":null,"executionTime":562,"lastExecutedAt":1756646496975,"lastExecutedByKernel":"bf0a0fc5-6447-488b-8a3a-f36c7d94327a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Implement model creation and training here\n# Use as many cells as you need\n\n# Full, robust solution — run in one cell\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score as _r2_score\n\n# -------------------------\n# Load data\n# -------------------------\ninsurance = pd.read_csv(\"insurance.csv\")\nvalidation_data = pd.read_csv(\"validation_dataset.csv\")\n\n# -------------------------\n# Clean target: 'charges'\n# -------------------------\n# Remove dollar signs and commas, coerce to float\ninsurance['charges'] = (insurance['charges']\n                        .astype(str)\n                        .str.replace(r'[\\$,]', '', regex=True)\n                        .str.strip()\n                        .replace('', np.nan)\n                        .astype(float))\n\n# -------------------------\n# Define columns\n# -------------------------\ncategorical_cols = ['sex', 'smoker', 'region']\nnumeric_cols = ['age', 'bmi', 'children']\n\n# Basic standardization of string categories (helps avoid small text mismatches)\nfor c in categorical_cols:\n    insurance[c] = insurance[c].astype(str).str.strip().str.lower()\n    # if validation has these columns, standardize them too (if column missing we'll handle later)\n    if c in validation_data.columns:\n        validation_data[c] = validation_data[c].astype(str).str.strip().str.lower()\n\n# Ensure numeric columns are numeric\ninsurance[numeric_cols] = insurance[numeric_cols].apply(pd.to_numeric, errors='coerce')\nvalidation_data[numeric_cols] = validation_data[numeric_cols].apply(pd.to_numeric, errors='coerce')\n\n# Drop rows in training that still have missing critical values\ninsurance = insurance.dropna(subset=numeric_cols + categorical_cols + ['charges'])\n\n# Split features/target\nX = insurance.drop(columns=['charges'])\ny = insurance['charges']\n\n# -------------------------\n# Preprocessing + model pipeline\n# - numeric: median imputation\n# - categorical: constant imputer + OneHotEncoder(handle_unknown='ignore')\n# -------------------------\nnum_transformer = SimpleImputer(strategy='median')\ncat_transformer = Pipeline([\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', num_transformer, numeric_cols),\n    ('cat', cat_transformer, categorical_cols)\n], remainder='drop')   # drop any other columns\n\nmodel = Pipeline([\n    ('pre', preprocessor),\n    ('reg', RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1))\n])\n\n# -------------------------\n# Train / evaluate\n# -------------------------\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nmodel.fit(X_train, y_train)\ny_pred_test = model.predict(X_test)\n\n# save R^2 in variable r2_score as required\nr2_score = float(_r2_score(y_test, y_pred_test))\nprint(\"R^2 on holdout test set:\", r2_score)\n\n# -------------------------\n# Predict on validation set\n# -------------------------\n# Ensure validation contains required feature columns; if not, add missing columns filled with NaN\nfor c in numeric_cols + categorical_cols:\n    if c not in validation_data.columns:\n        validation_data[c] = np.nan\n\n# Make predictions (preprocessor handles missing values)\nval_X = validation_data[numeric_cols + categorical_cols]\nvalidation_preds = model.predict(val_X)\n\n# Enforce minimum charge of 1000\nvalidation_data['predicted_charges'] = np.maximum(validation_preds, 1000.0)\n\n# Final object required by the task:\n# - r2_score  (float)\n# - validation_data  (pandas DataFrame, with 'predicted_charges' column)\nprint(\"\\nSample predictions:\")\nprint(validation_data[['predicted_charges']].head())\n\n# validation_data is the final DataFrame requested\n","outputsMetadata":{"0":{"height":206,"type":"stream"}}},"id":"a143c3b2-1ff1-47a0-8fc6-662b8b19dbf1","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"R^2 on holdout test set: 0.8001308602531637\n\nSample predictions:\n   predicted_charges\n0        3173.637163\n1       20345.595443\n2       18516.302949\n3       49032.662032\n4        7119.909259\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}